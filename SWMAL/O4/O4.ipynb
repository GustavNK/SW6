{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ae7416",
   "metadata": {},
   "source": [
    "# O4 genkendelse af manipulerede billeder, af ansigter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35555f8",
   "metadata": {},
   "source": [
    "## Overvejser\n",
    "\n",
    "### Datasættet\n",
    "- Alle ansigter er centreret\n",
    "- Mulighed for at fjerne detaljer i hjørner. Vi er meget specifikt intresseret i mund, næse & øjne\n",
    "- G fold cross validation til at lave trænings og validerings sæt\n",
    "- Alle billeder samme størrelse, derfor ikke brug for padding filter\n",
    "- feature scaling (smid filter til at nedvurderer hjørner af billeder, da der sjælendt er ansigt i hjørnerne) #preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d0956",
   "metadata": {},
   "source": [
    "## Code and implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422019e",
   "metadata": {},
   "source": [
    "### Imports and frameworks\n",
    "Here we import the necesarry libraries and frameworks which we will use in the generation of our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fbcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and other modules we use\n",
    "import os # Directory and file reading\n",
    "import re # Regex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IImage\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We should probably use keras since we want the make an CNN and possibly use our GPU\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004e62e",
   "metadata": {},
   "source": [
    "### Constants and custom hyperparameters\n",
    "Following are some of our custom hyperparameters which change some of the preprocessing changes we make to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4800fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_filter = True # Should we apply a darkening border filter to the images. Since the faces are mostly centered.\n",
    "test_size = 0.25 # Amount of test data. Value is normalized eg. 0.25 = 25%\n",
    "#difficulties = ['easy'] # Could be used to choose what images we would like to\n",
    "\n",
    "# Images are fetched from https://www.kaggle.com/ciplab/real-and-fake-face-detection\n",
    "\n",
    "# !!!!!!!!!!!! make the paths relative from the notebook !!!!!!!!!!!!!!!\n",
    "fake_dir = \"C:/Projects/SWMAL/real_and_fake_face/training_fake\" #Directory for fake images\n",
    "real_dir = \"C:/Projects/SWMAL/real_and_fake_face/training_real\" #Directory for real images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8f212",
   "metadata": {},
   "source": [
    "### Generation of input array\n",
    "This step fetches all images and loads them into the X array. All images are of the size 600x600 with RGB values from 0 to 255. This makes the images have the shape (600, 600, 3)\n",
    "\n",
    "\n",
    "This array includes both the fake and the real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a90346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1321, 600, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "fake = os.listdir(fake_dir)\n",
    "real = os.listdir(real_dir)\n",
    "pattern = \"(\\w+)_(\\d+)_(\\d)(\\d)(\\d)(\\d).jpg\"\n",
    "\n",
    "\n",
    "# Open images and insert into list\n",
    "X = []  # We insert all images into the same list, as we use train_test_split and K-fold to split the data\n",
    "\n",
    "# !!! This takes time !!!\n",
    "\n",
    "for n in fake:\n",
    "    result = re.match(pattern, n)\n",
    "    if result.group(1) == 'easy':\n",
    "        X.append(np.array(Image.open(fake_dir + \"/\"+ n)))\n",
    "\n",
    "for n in real:#[0: 10]:\n",
    "    X.append(np.array(Image.open(real_dir + \"/\"+ n)))\n",
    "\n",
    "# Show example image\n",
    "IImage(filename= fake_dir + \"/\" + fake[1])\n",
    "\n",
    "# Be sure that the images are in a correct format (The first param (2041) might be removed or changed depending on the specific dataset)\n",
    "print(np.shape(X))\n",
    "#print(X)\n",
    "#assert np.shape(X) == (2041, 600, 600, 3)\n",
    "x_np = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b05b7",
   "metadata": {},
   "source": [
    "### Generation of result array\n",
    "Just as with the input array we generate an output array with the correct answers.\n",
    "This includes which part of the image is edited. By default all real images will have [0,0,0,0] as the result otherwise the results adhear to the following syntax:\n",
    "\n",
    "['left eye','right eye','nose','mouth']\n",
    "\n",
    "All answers are in binary form. eg. [0,1,0,1] = Right eye and mouth changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672ea96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pattern for matching difficulty aswell as changed parts of the face\n",
    "pattern = \"(\\w+)_(\\d+)_(\\d)(\\d)(\\d)(\\d).jpg\"\n",
    "\n",
    "# Result array\n",
    "y = []\n",
    "\n",
    "# Array of difficulties\n",
    "type_list = []\n",
    "\n",
    "# Create results for fake images\n",
    "dir_list = os.listdir(fake_dir)\n",
    "for i in dir_list:\n",
    "    result = re.match(pattern, i)\n",
    "    if result.group(1) == 'easy':\n",
    "        #acc = []\n",
    "        #\n",
    "        result = re.match(pattern, i)\n",
    "        #left, right, nose, mouth = result.group(3, 4, 5, 6)\n",
    "        #\n",
    "        #acc.append(int(left))\n",
    "        #acc.append(int(right))\n",
    "        #acc.append(int(nose))\n",
    "        #acc.append(int(mouth))\n",
    "        type_list.append(result.group(1))\n",
    "        #y.append(acc)\n",
    "        y.append(1)\n",
    "\n",
    "    \n",
    "# Create result for real images\n",
    "dir_list = os.listdir(real_dir)\n",
    "for i in dir_list:\n",
    "    #acc = []    \n",
    "    #acc.append(0)\n",
    "    #acc.append(0)\n",
    "    #acc.append(0)\n",
    "    #acc.append(0)\n",
    "    #type_list.append(\"real\")\n",
    "    #y.append(acc)\n",
    "    y.append(0)\n",
    "    \n",
    "y_np = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71643b",
   "metadata": {},
   "source": [
    "### Preprocessing of all data\n",
    "\n",
    "Since most of the faces are already centered we would like the turn down some of the features of the corners, which we already know doesnt include very much interesting data about if the photo is manipulated or not.\n",
    "\n",
    "Therefore we apply a filter which darkens the edges of the images. This is done to all images (both real and fake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bf5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_filter:\n",
    "    # Create filter\n",
    "\n",
    "    # Apply filter to all images\n",
    "\n",
    "    # Results stay the same\n",
    "    a = True # remove when actually code written"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208e0a4",
   "metadata": {},
   "source": [
    "### Splitting the data into test and training data\n",
    "First we want to randomly split the data into a training and a test set. This is done with train_test_split, where we use 25% of the data as test data.\n",
    "\n",
    "After this we use K-fold with cross validation to try and get the most out of the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5283535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training size:\t990\n",
      "test size:\t331\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_np, y_np, test_size=test_size, random_state=42)\n",
    "\n",
    "assert len(x_train) == len(y_train) and len(x_test) == len(y_test) \n",
    "\n",
    "print(f\"\"\"\n",
    "training size:\\t{len(x_train)}\n",
    "test size:\\t{len(x_test)}\"\"\")\n",
    "print(y_test)\n",
    "\n",
    "#generate the fold object\n",
    "#kf = KFold(n_splits=2)\n",
    "# The kfold object will return the indices of the splits in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b2ad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 598, 598, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 299, 299, 6)      0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 297, 297, 32)      1760      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 148, 148, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 700928)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 60)                42055740  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                1830      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,059,529\n",
      "Trainable params: 42,059,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Base model, LeNET5\n",
    "seq = keras.Sequential()\n",
    "\n",
    "seq.add(layers.Conv2D(filters=6, kernel_size=(3,3), activation='relu', input_shape=(600,600,3)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "\n",
    "seq.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "seq.add(layers.MaxPooling2D())\n",
    "\n",
    "seq.add(layers.Flatten())\n",
    "\n",
    "seq.add(layers.Dense(units=60, activation='relu'))\n",
    "seq.add(layers.Dense(units=30, activation='relu'))\n",
    "seq.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "seq.summary()\n",
    "\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#seq.compile(optimizer='sgd', loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy()]) # optimizer='SGD', loss='MSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8017da60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_26\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (600, 600, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GUSTAV~1\\AppData\\Local\\Temp/ipykernel_48756/50949254.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m ])\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    438\u001b[0m               'method accepts an `inputs` argument.')\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m           raise ValueError('You cannot build your model by calling `build` '\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[0;32m    229\u001b[0m                          \u001b[1;34m'is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                          \u001b[1;34mf'expected min_ndim={spec.min_ndim}, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv2d_26\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (600, 600, 3)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "\n",
    "data_aug = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "resize_and_rescale = keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(600,600),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
    "])\n",
    "input_shape=(600,600,3)\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_aug,\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape = input_shape),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(3, activation= 'softmax'),\n",
    "    \n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)\n",
    "\n",
    "mode.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seq.predict(x_test)\n",
    "print(results)\n",
    "\n",
    "y_pred = []\n",
    "for r in results:\n",
    "    y_pred.append(r >=0.5)\n",
    "#print(len(y_pred))\n",
    "#print(len(y_test))\n",
    "\n",
    "correct_guess = []\n",
    "for index in range(0,len(y_pred)):\n",
    "    print(f\"\"\"y_pred : {y_pred[index]}\\ny_test:{y_test[index]}\\ncompared:{y_pred[index] == y_test[index]}\\n\"\"\")\n",
    "    correct_guess.append(y_pred[index] == y_test[index])\n",
    "    \n",
    "#print(correct_guess)\n",
    "print(seq.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.count(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acc325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
