{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "\n",
    "Excercise 9 from [HOML], p496  (slighty modified)::\n",
    "\n",
    "__\"9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\"__\n",
    "\n",
    "For the journal: \n",
    "\n",
    "* write an introduction to CNNs (what are CNNs, what is a convolution layer, etc..), \n",
    "* document your experiments towards the end-goal of reaching 'a high accuracy' (what did you try, what work/did not work), \n",
    "* document how you use '_generalization_' in your setup (us of simple hold-out/train-test split or k-fold, or etc..),\n",
    "* produce some sort of '_learning-curve_' that illustrates the drop in cost- or increase in score-function with respect to, say training iteration (for inspiration see fig 4.20, 10-12 or 10.17 in [HOML])\n",
    "* document the final CNN setup (layers etc., perhaps as a graph/drawing), \n",
    "* discus on your iterations towards the end-goal and other findings you had,\n",
    "* and, as always, write a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical #This works dont worry\n",
    "\n",
    "\n",
    "def MNIST_InitData():\n",
    "    return fetch_openml('mnist_784', return_X_y=True, cache=True, as_frame=False)\n",
    "\n",
    "def MNIST_GetDataSet(X):\n",
    "    return (X / 255)\n",
    "\n",
    "MNIST_X, MNIST_Y = MNIST_InitData()\n",
    "MNIST_X = MNIST_GetDataSet(MNIST_X)\n",
    "\n",
    "reshaped_MNIST_X = MNIST_X.reshape(len(MNIST_X), 28, 28)\n",
    "print(reshaped_MNIST_X.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(reshaped_MNIST_X, MNIST_Y, test_size=0.2, random_state=69)\n",
    "y_train = to_categorical(y_train, dtype =\"uint8\")\n",
    "y_test = to_categorical(y_test, dtype =\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 28, 28)\n",
      "(14000, 10)\n",
      "(14000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array that holds all the compiled models\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BASE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_53 (Conv2D)          (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d_36 (Avera  (None, 13, 13, 6)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 11, 11, 32)        1760      \n",
      "                                                                 \n",
      " average_pooling2d_37 (Avera  (None, 5, 5, 32)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 120)               96120     \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,954\n",
      "Trainable params: 108,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# BASE\n",
    "seq = keras.Sequential(name=\"BASE\")\n",
    "\n",
    "seq.add(layers.Conv2D(filters= 6, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "\n",
    "seq.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "\n",
    "seq.add(layers.Flatten())\n",
    "\n",
    "seq.add(layers.Dense(units=120, activation='relu'))\n",
    "seq.add(layers.Dense(units=84, activation='relu'))\n",
    "seq.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "seq.summary()\n",
    "\n",
    "seq.compile(optimizer='sgd', loss=keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "),metrics=[keras.metrics.Accuracy()]) # optimizer='SGD', loss='MSE'\n",
    "\n",
    "models.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ADAM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 13, 13, 6)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 11, 11, 32)        1760      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 5, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 120)               96120     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,954\n",
      "Trainable params: 108,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# Use Adam & MaxPooling\n",
    "\n",
    "seq = keras.Sequential(name=\"ADAM\")\n",
    "\n",
    "seq.add(layers.Conv2D(filters= 6, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.MaxPooling2D())\n",
    "\n",
    "seq.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.MaxPooling2D())\n",
    "\n",
    "seq.add(layers.Flatten())\n",
    "\n",
    "seq.add(layers.Dense(units=120, activation='relu'))\n",
    "seq.add(layers.Dense(units=84, activation='relu'))\n",
    "seq.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "seq.summary()\n",
    "\n",
    "seq.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "),metrics=[keras.metrics.Accuracy()]) # optimizer='SGD', loss='MSE'\n",
    "\n",
    "models.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv2D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_57 (Conv2D)          (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d_38 (Avera  (None, 13, 13, 6)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 11, 11, 16)        880       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 5, 5, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 3, 3, 16)          2320      \n",
      "                                                                 \n",
      " average_pooling2d_39 (Avera  (None, 1, 1, 16)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 120)               2040      \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,314\n",
      "Trainable params: 16,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# Use extra Conv2D\n",
    "\n",
    "seq = keras.Sequential(name=\"Conv2D\")\n",
    "\n",
    "seq.add(layers.Conv2D(filters= 6, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "seq.add(layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.MaxPooling2D())\n",
    "seq.add(layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "\n",
    "seq.add(layers.Flatten())\n",
    "\n",
    "seq.add(layers.Dense(units=120, activation='relu'))\n",
    "seq.add(layers.Dense(units=84, activation='relu'))\n",
    "seq.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "seq.summary()\n",
    "\n",
    "seq.compile(optimizer='sgd', loss=keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "),metrics=[keras.metrics.Accuracy()]) # optimizer='SGD', loss='MSE'\n",
    "\n",
    "models.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " average_pooling2d_40 (Avera  (None, 13, 13, 6)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 11, 11, 32)        1760      \n",
      "                                                                 \n",
      " average_pooling2d_41 (Avera  (None, 5, 5, 32)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 120)               96120     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 10)                1210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,150\n",
      "Trainable params: 99,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# remove Dense layer\n",
    "\n",
    "seq = keras.Sequential(name=\"Dense\")\n",
    "\n",
    "seq.add(layers.Conv2D(filters= 6, kernel_size=(3,3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "\n",
    "seq.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "seq.add(layers.AveragePooling2D())\n",
    "\n",
    "seq.add(layers.Flatten())\n",
    "\n",
    "seq.add(layers.Dense(units=120, activation='relu'))\n",
    "seq.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "seq.summary()\n",
    "\n",
    "seq.compile(optimizer='sgd', loss=keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "),metrics=[keras.metrics.Accuracy()]) # optimizer='SGD', loss='MSE'\n",
    "\n",
    "models.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model BASE:\n",
      "\tEpoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rasmus\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTime elapsed = 79.0\n",
      "\tEpoch 1\n",
      "\tTime elapsed = 71.0\n",
      "\tEpoch 2\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 3\n",
      "\tTime elapsed = 71.0\n",
      "\tEpoch 4\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 5\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 6\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 7\n",
      "\tTime elapsed = 69.0\n",
      "\tEpoch 8\n",
      "\tTime elapsed = 68.0\n",
      "\tEpoch 9\n",
      "\tTime elapsed = 70.0\n",
      "Train results:\n",
      "loss: 0.29256228 \t- acc: 0.00000000\n",
      "loss: 0.19548905 \t- acc: 0.00000179\n",
      "loss: 0.14913721 \t- acc: 0.00000357\n",
      "loss: 0.11614167 \t- acc: 0.00003214\n",
      "loss: 0.10271072 \t- acc: 0.00003929\n",
      "loss: 0.09138685 \t- acc: 0.00018929\n",
      "loss: 0.10323255 \t- acc: 0.00030536\n",
      "loss: 0.08153365 \t- acc: 0.00051250\n",
      "loss: 0.07787854 \t- acc: 0.00057143\n",
      "loss: 0.06307453 \t- acc: 0.00083036\n",
      "\n",
      "Test results:\n",
      "loss: 0.30082771 \t- acc: 0.00000000\n",
      "loss: 0.20379822 \t- acc: 0.00000000\n",
      "loss: 0.15754873 \t- acc: 0.00000714\n",
      "loss: 0.12734379 \t- acc: 0.00006429\n",
      "loss: 0.11655109 \t- acc: 0.00006429\n",
      "loss: 0.10630090 \t- acc: 0.00017143\n",
      "loss: 0.11675653 \t- acc: 0.00036429\n",
      "loss: 0.09722948 \t- acc: 0.00054286\n",
      "loss: 0.09470630 \t- acc: 0.00063571\n",
      "loss: 0.08043518 \t- acc: 0.00096429\n",
      "Model ADAM:\n",
      "\tEpoch 0\n",
      "\tTime elapsed = 76.0\n",
      "\tEpoch 1\n",
      "\tTime elapsed = 80.0\n",
      "\tEpoch 2\n",
      "\tTime elapsed = 79.0\n",
      "\tEpoch 3\n",
      "\tTime elapsed = 74.0\n",
      "\tEpoch 4\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 5\n",
      "\tTime elapsed = 73.0\n",
      "\tEpoch 6\n",
      "\tTime elapsed = 73.0\n",
      "\tEpoch 7\n",
      "\tTime elapsed = 73.0\n",
      "\tEpoch 8\n",
      "\tTime elapsed = 72.0\n",
      "\tEpoch 9\n",
      "\tTime elapsed = 73.0\n",
      "Train results:\n",
      "loss: 0.05477408 \t- acc: 0.00015000\n",
      "loss: 0.04112042 \t- acc: 0.00004821\n",
      "loss: 0.02582140 \t- acc: 0.00158750\n",
      "loss: 0.01732083 \t- acc: 0.00333036\n",
      "loss: 0.02498582 \t- acc: 0.01186250\n",
      "loss: 0.01453055 \t- acc: 0.01784464\n",
      "loss: 0.01223307 \t- acc: 0.02858750\n",
      "loss: 0.00630649 \t- acc: 0.02808571\n",
      "loss: 0.01015012 \t- acc: 0.04048571\n",
      "loss: 0.00771629 \t- acc: 0.04943928\n",
      "\n",
      "Test results:\n",
      "loss: 0.06670877 \t- acc: 0.00013571\n",
      "loss: 0.05420197 \t- acc: 0.00007143\n",
      "loss: 0.04368519 \t- acc: 0.00149286\n",
      "loss: 0.04038462 \t- acc: 0.00336429\n",
      "loss: 0.05444901 \t- acc: 0.01224286\n",
      "loss: 0.04580345 \t- acc: 0.01756429\n",
      "loss: 0.04356413 \t- acc: 0.02842143\n",
      "loss: 0.03945009 \t- acc: 0.02740000\n",
      "loss: 0.04635417 \t- acc: 0.03950714\n",
      "loss: 0.05046201 \t- acc: 0.04847143\n",
      "Model Conv2D:\n",
      "\tEpoch 0\n",
      "\tTime elapsed = 74.0\n",
      "\tEpoch 1\n",
      "\tTime elapsed = 73.0\n",
      "\tEpoch 2\n",
      "\tTime elapsed = 69.0\n",
      "\tEpoch 3\n",
      "\tTime elapsed = 68.0\n",
      "\tEpoch 4\n",
      "\tTime elapsed = 76.0\n",
      "\tEpoch 5\n",
      "\tTime elapsed = 72.0\n",
      "\tEpoch 6\n",
      "\tTime elapsed = 68.0\n",
      "\tEpoch 7\n",
      "\tTime elapsed = 71.0\n",
      "\tEpoch 8\n",
      "\tTime elapsed = 74.0\n",
      "\tEpoch 9\n",
      "\tTime elapsed = 69.0\n",
      "Train results:\n",
      "loss: 0.70301324 \t- acc: 0.00000000\n",
      "loss: 0.33995891 \t- acc: 0.00000000\n",
      "loss: 0.27250272 \t- acc: 0.00000000\n",
      "loss: 0.18833557 \t- acc: 0.00000000\n",
      "loss: 0.15664174 \t- acc: 0.00000000\n",
      "loss: 0.15489358 \t- acc: 0.00000000\n",
      "loss: 0.14177045 \t- acc: 0.00000000\n",
      "loss: 0.13867143 \t- acc: 0.00003750\n",
      "loss: 0.10823317 \t- acc: 0.00001250\n",
      "loss: 0.10853525 \t- acc: 0.00000714\n",
      "\n",
      "Test results:\n",
      "loss: 0.71014357 \t- acc: 0.00000000\n",
      "loss: 0.34284136 \t- acc: 0.00000000\n",
      "loss: 0.27427137 \t- acc: 0.00000000\n",
      "loss: 0.19142869 \t- acc: 0.00000000\n",
      "loss: 0.16013379 \t- acc: 0.00000000\n",
      "loss: 0.16097902 \t- acc: 0.00000000\n",
      "loss: 0.15103644 \t- acc: 0.00000000\n",
      "loss: 0.14801387 \t- acc: 0.00000000\n",
      "loss: 0.11772136 \t- acc: 0.00000714\n",
      "loss: 0.11936218 \t- acc: 0.00000000\n",
      "Model Dense:\n",
      "\tEpoch 0\n",
      "\tTime elapsed = 73.0\n",
      "\tEpoch 1\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 2\n",
      "\tTime elapsed = 72.0\n",
      "\tEpoch 3\n",
      "\tTime elapsed = 68.0\n",
      "\tEpoch 4\n",
      "\tTime elapsed = 69.0\n",
      "\tEpoch 5\n",
      "\tTime elapsed = 70.0\n",
      "\tEpoch 6\n",
      "\tTime elapsed = 78.0\n",
      "\tEpoch 7\n",
      "\tTime elapsed = 69.0\n",
      "\tEpoch 8\n",
      "\tTime elapsed = 69.0\n",
      "\tEpoch 9\n",
      "\tTime elapsed = 68.0\n",
      "Train results:\n",
      "loss: 2.29974890 \t- acc: 0.00000000\n",
      "loss: 2.28380275 \t- acc: 0.00000000\n",
      "loss: 1.99108624 \t- acc: 0.00000000\n",
      "loss: 0.64531618 \t- acc: 0.00000000\n",
      "loss: 0.46064755 \t- acc: 0.00000000\n",
      "loss: 0.39894578 \t- acc: 0.00000000\n",
      "loss: 0.37212434 \t- acc: 0.00000000\n",
      "loss: 0.35906777 \t- acc: 0.00000000\n",
      "loss: 0.32597178 \t- acc: 0.00000000\n",
      "loss: 0.30786261 \t- acc: 0.00000000\n",
      "\n",
      "Test results:\n",
      "loss: 2.29968381 \t- acc: 0.00000000\n",
      "loss: 2.28465772 \t- acc: 0.00000000\n",
      "loss: 1.99431574 \t- acc: 0.00000000\n",
      "loss: 0.65281099 \t- acc: 0.00000000\n",
      "loss: 0.46415046 \t- acc: 0.00000000\n",
      "loss: 0.39982456 \t- acc: 0.00000000\n",
      "loss: 0.37446338 \t- acc: 0.00000000\n",
      "loss: 0.35748279 \t- acc: 0.00000000\n",
      "loss: 0.32661411 \t- acc: 0.00000000\n",
      "loss: 0.30924013 \t- acc: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_results = {}\n",
    "\n",
    "total_start_time = time.time()\n",
    "# For each model fit 10 epochs and for each epoch save the eval for train and test datasets\n",
    "for model in models:\n",
    "    train_results = []\n",
    "    test_results = []\n",
    "    print(\"Model %s:\" % (model.name))\n",
    "\n",
    "    for i in range(10):\n",
    "        print('\\tEpoch %d' % (i))\n",
    "        start_time = time.time()\n",
    "        model.fit(x_train, y_train, epochs=1, verbose=0)\n",
    "        train_val = model.evaluate(x_train, y_train, verbose=0)\n",
    "        train_results.append(train_val)\n",
    "        test_val = model.evaluate(x_test, y_test, verbose=0)\n",
    "        test_results.append(test_val)\n",
    "        print(\"\\tTime elapsed = {0} sec\".format(round(time.time()-start_time,2)))\n",
    "\n",
    "    model_results[model.name] = (train_results, test_results)\n",
    "    print('Train results:')\n",
    "    for tval in train_results:\n",
    "        print(\"loss: %5.8f \\t- acc: %5.8f\" % (tval[0], tval[1]))\n",
    "\n",
    "    print('\\nTest results:')\n",
    "    for tval in test_results:\n",
    "        print(\"loss: %5.8f \\t- acc: %5.8f\" % (tval[0], tval[1]))\n",
    "\n",
    "print(\"\\tTime elapsed = {0} sec\".format(round(time.time()-total_start_time,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Dense layer\n",
      "Train results:\n",
      "loss: 0.27132291 \t- acc: 0.00000000\n",
      "loss: 0.19789621 \t- acc: 0.00007679\n",
      "loss: 0.15082665 \t- acc: 0.00000357\n",
      "loss: 0.12329338 \t- acc: 0.00007500\n",
      "loss: 0.11290929 \t- acc: 0.00002143\n",
      "\n",
      "Test results:\n",
      "loss: 0.27190727 \t- acc: 0.00000000\n",
      "loss: 0.20477143 \t- acc: 0.00009286\n",
      "loss: 0.15918493 \t- acc: 0.00000000\n",
      "loss: 0.13293028 \t- acc: 0.00012143\n",
      "loss: 0.12209960 \t- acc: 0.00005714\n"
     ]
    }
   ],
   "source": [
    "print(seq.name)\n",
    "\n",
    "print('Train results:')\n",
    "for tval in train_results:\n",
    "    print(\"loss: %5.8f \\t- acc: %5.8f\" % (tval[0], tval[1]))\n",
    "\n",
    "print('\\nTest results:')\n",
    "for tval in test_results:\n",
    "    print(\"loss: %5.8f \\t- acc: %5.8f\" % (tval[0], tval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.1470075e-01 1.6290819e-08 1.8611152e-03 ... 2.0238457e-04\n",
      "  2.5736915e-03 2.9833813e-04]\n",
      " [2.1608108e-04 6.2580562e-01 1.6144083e-01 ... 4.3501183e-03\n",
      "  2.5767220e-02 2.3605800e-03]\n",
      " [2.8630038e-04 3.6705823e-03 3.7862506e-02 ... 3.3295149e-04\n",
      "  3.9914619e-02 1.0040342e-02]\n",
      " ...\n",
      " [5.2151759e-04 8.4010577e-03 4.9488333e-01 ... 6.8453453e-03\n",
      "  1.9727719e-01 3.0113619e-03]\n",
      " [4.0944951e-04 8.2575264e-07 5.5926446e-02 ... 4.3923959e-05\n",
      "  7.2406110e-04 6.3879648e-04]\n",
      " [7.8199673e-01 1.4679162e-07 1.4951080e-02 ... 5.4814718e-05\n",
      "  2.7454974e-02 3.6626324e-04]]\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6409 - accuracy: 0.0000e+00\n",
      "[0.6409022212028503, 0.0]\n"
     ]
    }
   ],
   "source": [
    "results = seq.predict(x_test)\n",
    "print(results)\n",
    "print(seq.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "utils.plot_model(\n",
    "    seq,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    "---------||\n",
    "2021-10-20| CEF, initial version, clone from [HOML].\n",
    "2021-10-26| CEF, added learning curve item.\n",
    "2022-01-25| CEF, update to SWMAL F22.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
